# 基本概念
机器学习，致力于研究如何通过**计算的手段**，**利用经验**来改善系统自身的性能。

- 研究的主要内容：在计算机上从数据中产生“**模型**”（**model**）的算法，即“**学习算法**”（**learning algorithm**）
    - 将经验数据给它，它就能基于这些数据产生模型
    - 在面对新情况的时候，模型会给我提供相应的判断
    - 这里的模型是指从数据中学得（训练）的结果，非如决策树一般的全局性结果或一条规则的局部性结果

# 基本术语
- **数据集（data set）** 由一条条记录组成
    - **记录**是关于一个事件或对象的描述，又称为“示例”（**instance**）或“样本”（**sample**）
    - **属性 attribute** 反映事件或对象在某个方面的表现或性质的事项，又称“特征”**feature**
    - **属性值 attribute value** 属性上的取值
    - **属性空间 attribute space** 属性张成的空间，又称**样本空间、输入空间**

        >把记录理解为一个数组，属性就是数组中的元素，多少个属性就是多少维数组，然后对应到空间上，就是多维空间

    - **特征向量 feature vector** 相应的，每条记录就可以形成一个坐标，所以也把示例称为特征向量

> 一般的，令
>```math
>D = \{ x_1, x_2, x_3,...,x_m \}
>```
>表示包含*m*个示例的**数据集**，则每个示例

- **学习（learning） 训练（training）** 从数据中学得模型的过程，
- **训练数据**
- **训练样本**，数据中的每一条记录
- **训练集**，即训练数据
- **假设 hypothesis** 关于数据的某种潜在的规律
- **真相 真实 ground-truth** 潜在规律自身
- 模型又称**学习器 learner**
> 学习算法通常有参数需要设置，使用不同的参数值和训练数据，将产生不同的结果
---
- **标记** 关于示例结果的信息
- **样例** 拥有了标记信息的示例
> 若将标记看作对象本身的一部分，则样例也称为样本
- **标记空间** 所有标记的集合
- **测试** testing，学得模型后，使用其进行预测的过程；被预测的样本称为**预测样本**
#### 学习任务
- **分类 classification** 预测的是离散值。对只涉及两个类别的为**二分类 binary classification**（正类、反/负类），涉及多个类别，称为**多分类 multi-class classification**
- **回归 regression** 预测的是连续值

一般的，预测任务是系统通过对训练集$\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}$进行学习,建立一个从输入空间$X$到输出空间$Y$的映射$f:X \rightarrow Y$.对二分类任务通常令$Y=\{-1,+1\} 或 \{0,0\};对多分类任务，$|Y|>2$；对回归任务，$Y=R$,R为实数集$

- **聚类 clustering** 将训练样本分成若干组，每组称为一个**簇 cluster**；这些自动形成的簇可能对应一些潜在的概念划分，而*这样的概念我们实现是不知道的*，而且学习过程中使用的训练样本通常**不拥有标记信息**

>根据训练数据是否拥有标记信息，学习任务可分为**监督学习 supervised learning**和**无监督学习 unsupervised learning**,分类和回归是前者的代表，聚类是后者的代表

- **泛化 generalization 能力** 学得模型适用于新样本的能力
>通常假设样本空间中全体样本服从一个位置**分布 distribution** $D$,我们获得的每个样本都是独立地从这个分布上采样获得的，即**独立同分布 independent and indentically distributed**。*一般而言，训练样本越多，我们得到的关于$D$的信息越多，这样越有可能通过学习获得具有强泛化能力的模型。*

# 假设空间
由于我们不可能将所有情况都训练到，所以学习过程就看作以个在所有假设（hypothesis）组成的空间中进行搜索的过程，搜索目标是找到与训练集**匹配**fit的假设。

可以有许多测量队这个假设空间进行搜索，如自顶向下、从一般到特殊，或是自底向上、从特殊到一般，搜索过程中可以不断删除与正例不一致的假设、和与范反例一致的假设。*最终将会获得与训练集一致的假设（即对所有训练样本能够进行正确的判断）*，这就是我们学得的结果。

像是问题中我们常面临很大的假设空间，但学习过程是基于有限样本训练集进行的，因此，可能有多个假设与训练集一致，**即存在着一个与训练集一致的“假设集合”**，称之为**版本空间 version space**。

# 归纳偏好
>通过学习得到的模型对应了假设空间的一个假设，而若有多个与训练集一致的假设，与他们对应的模型在面临新样本的时候，却会产生不同的输出，那应该采用什么模型？

机器学习算法在学习过程中对某种类型假设的偏好，称为**归纳偏好** inductive bias
任何一个有效的机器学习算法**必有其归纳偏好**，否则它将被假设空间中看似在训练集上等效的假设所迷惑，而无法产生确定的学习结果。

那么有没有一般性的原则来引导算法确立“正确的”偏好呢？

**奥卡姆剃刀** 是一种常用的、自然科学研究中最基本的原则，即“若有多个假设与观察一致，则选择最简单的那个”。

>归纳偏好对应了学习算法本身所做出的的关于“什么样的模型更好”的假设。这个假设是否成立，即算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能够取得好的性能。
---
>当学习的目标函数与样本空间为均匀分布，通过证明，**无论采用什么算法，他们的期望性是相同的**，这称之为“没有免费的午餐”定理 *No Free Lunch Theorem  --NFL*

但事实上，很多时候并非均匀分布。所以，我们应该清楚的认识到，**脱离具体问题，空泛地谈论“什么学习算法更好”毫无意义**。要谈论算法的相对优劣，必须要针对具体的学习问题；学习算法自身的归纳偏好与问题是否相匹配，往往会起到决定性作用。

---
## 其他概念
大数据时代的三大关键技术：
- **机器学习** 提供数据分析能力
- **云计算** 提供数据处理能力
- **众包** crowdsourcing 提供数据标记能力

机器学习领域和数据库领域是数据挖掘的两大支撑。
- 机器学习为数据挖掘提供数据分析技术
- 数据库为数据挖掘提供数据管理技术
